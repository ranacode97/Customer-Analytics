{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "600ea747-75e2-4125-a161-c76984392d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing trial store: 77\n",
      "Best control store for trial store 77: 1.0\n",
      "Pre-trial period data for scaled_control_sales:\n",
      "   STORE_NBR YEARMONTH  totSales  scaled_control_sales\n",
      "0          1   2018-07     206.9            253.459586\n",
      "1          1   2018-08     176.1            215.728531\n",
      "2          1   2018-09     278.8            341.539549\n",
      "3          1   2018-10     188.1            230.428942\n",
      "4          1   2018-11     192.6            235.941596\n",
      "5          1   2018-12     189.6            232.266494\n",
      "6          1   2019-01     154.8            189.635302\n",
      "Trial period data for scaled_control_sales:\n",
      "   STORE_NBR YEARMONTH  totSales  scaled_control_sales\n",
      "7          1   2019-02     225.4            276.122720\n",
      "8          1   2019-03     192.9            236.309107\n",
      "9          1   2019-04     192.9            236.309107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fd/nbl9w7k13q1bwkd9p9zpsd5c0000gn/T/ipykernel_43254/4008438654.py:114: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  percentage_diff = trial_period.groupby('YEARMONTH').apply(calculate_percentage_difference)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage differences during trial period for store 77:\n",
      "YEARMONTH\n",
      "2019-02   -0.148929\n",
      "2019-03    0.178541\n",
      "2019-04    0.115065\n",
      "Freq: M, dtype: float64\n",
      "Insufficient data for t-test between trial store 77 and control store 1.0.\n",
      "Processing trial store: 86\n",
      "Best control store for trial store 86: 1.0\n",
      "Pre-trial period data for scaled_control_sales:\n",
      "   STORE_NBR YEARMONTH  totSales  scaled_control_sales\n",
      "0          1   2018-07     206.9            912.969187\n",
      "1          1   2018-08     176.1            777.060772\n",
      "2          1   2018-09     278.8           1230.235907\n",
      "3          1   2018-10     188.1            830.012103\n",
      "4          1   2018-11     192.6            849.868851\n",
      "5          1   2018-12     189.6            836.631019\n",
      "6          1   2019-01     154.8            683.072161\n",
      "Trial period data for scaled_control_sales:\n",
      "   STORE_NBR YEARMONTH  totSales  scaled_control_sales\n",
      "7          1   2019-02     225.4            994.602488\n",
      "8          1   2019-03     192.9            851.192635\n",
      "9          1   2019-04     192.9            851.192635\n",
      "Percentage differences during trial period for store 86:\n",
      "YEARMONTH\n",
      "2019-02   -0.081844\n",
      "2019-03    0.206307\n",
      "2019-04   -0.003516\n",
      "Freq: M, dtype: float64\n",
      "Insufficient data for t-test between trial store 86 and control store 1.0.\n",
      "Processing trial store: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fd/nbl9w7k13q1bwkd9p9zpsd5c0000gn/T/ipykernel_43254/4008438654.py:114: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  percentage_diff = trial_period.groupby('YEARMONTH').apply(calculate_percentage_difference)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best control store for trial store 88: 1.0\n",
      "Pre-trial period data for scaled_control_sales:\n",
      "   STORE_NBR YEARMONTH  totSales  scaled_control_sales\n",
      "0          1   2018-07     206.9           1399.860725\n",
      "1          1   2018-08     176.1           1191.471599\n",
      "2          1   2018-09     278.8           1886.327551\n",
      "3          1   2018-10     188.1           1272.662167\n",
      "4          1   2018-11     192.6           1303.108631\n",
      "5          1   2018-12     189.6           1282.810989\n",
      "6          1   2019-01     154.8           1047.358339\n",
      "Trial period data for scaled_control_sales:\n",
      "   STORE_NBR YEARMONTH  totSales  scaled_control_sales\n",
      "7          1   2019-02     225.4           1525.029519\n",
      "8          1   2019-03     192.9           1305.138395\n",
      "9          1   2019-04     192.9           1305.138395\n",
      "Percentage differences during trial period for store 88:\n",
      "YEARMONTH\n",
      "2019-02   -0.101526\n",
      "2019-03    0.131834\n",
      "2019-04    0.102872\n",
      "Freq: M, dtype: float64\n",
      "Insufficient data for t-test between trial store 88 and control store 1.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fd/nbl9w7k13q1bwkd9p9zpsd5c0000gn/T/ipykernel_43254/4008438654.py:114: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  percentage_diff = trial_period.groupby('YEARMONTH').apply(calculate_percentage_difference)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid object type at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32mlib.pyx:2391\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid object type",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 137\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsufficient data for t-test between trial store \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_store\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and control store \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_control_store\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Visualize sales trends\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(data\u001b[38;5;241m=\u001b[39mmetrics, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYEARMONTH\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotSales\u001b[39m\u001b[38;5;124m'\u001b[39m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTORE_NBR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    138\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales Trends During Trial and Pre-Trial Periods\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    139\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/seaborn/relational.py:515\u001b[0m, in \u001b[0;36mlineplot\u001b[0;34m(data, x, y, hue, size, style, units, weights, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, estimator, errorbar, n_boot, seed, orient, sort, err_style, err_kws, legend, ci, ax, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m color \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    513\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _default_color(ax\u001b[38;5;241m.\u001b[39mplot, hue, color, kwargs)\n\u001b[0;32m--> 515\u001b[0m p\u001b[38;5;241m.\u001b[39mplot(ax, kwargs)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ax\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/seaborn/relational.py:276\u001b[0m, in \u001b[0;36m_LinePlotter.plot\u001b[0;34m(self, ax, kws)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# TODO How to handle NA? We don't want NA to propagate through to the\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# estimate/CI when some values are present, but we would also like\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# matplotlib to show \"gaps\" in the line when all values are missing.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    273\u001b[0m \n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Loop over the semantic subsets and add to the plot\u001b[39;00m\n\u001b[1;32m    275\u001b[0m grouping_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 276\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_vars, sub_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_data(grouping_vars, from_comp_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort:\n\u001b[1;32m    279\u001b[0m         sort_vars \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m\"\u001b[39m, orient, other]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/seaborn/_base.py:902\u001b[0m, in \u001b[0;36mVectorPlotter.iter_data\u001b[0;34m(self, grouping_vars, reverse, from_comp_data, by_facet, allow_empty, dropna)\u001b[0m\n\u001b[1;32m    899\u001b[0m grouping_vars \u001b[38;5;241m=\u001b[39m [var \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m grouping_vars \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables]\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_comp_data:\n\u001b[0;32m--> 902\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomp_data\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_data\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/seaborn/_base.py:1000\u001b[0m, in \u001b[0;36mVectorPlotter.comp_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_levels:\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;66;03m# TODO this should happen in some centralized location\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# it is similar to GH2419, but more complicated because\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# supporting `order` in categorical plots is tricky\u001b[39;00m\n\u001b[1;32m    999\u001b[0m     orig \u001b[38;5;241m=\u001b[39m orig[orig\u001b[38;5;241m.\u001b[39misin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_levels[var])]\n\u001b[0;32m-> 1000\u001b[0m comp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(converter\u001b[38;5;241m.\u001b[39mconvert_units(orig))\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m   1001\u001b[0m transform \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform\n\u001b[1;32m   1002\u001b[0m parts\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mSeries(transform(comp), orig\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39morig\u001b[38;5;241m.\u001b[39mname))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/tools/numeric.py:232\u001b[0m, in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast, dtype_backend)\u001b[0m\n\u001b[1;32m    230\u001b[0m coerce_numeric \u001b[38;5;241m=\u001b[39m errors \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     values, new_mask \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_numeric(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m    233\u001b[0m         values,\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28mset\u001b[39m(),\n\u001b[1;32m    235\u001b[0m         coerce_numeric\u001b[38;5;241m=\u001b[39mcoerce_numeric,\n\u001b[1;32m    236\u001b[0m         convert_to_masked_nullable\u001b[38;5;241m=\u001b[39mdtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values_dtype, StringDtype)\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m values_dtype\u001b[38;5;241m.\u001b[39mstorage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow_numpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    239\u001b[0m     )\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32mlib.pyx:2433\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid object type at position 0"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"QVI_data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Add a Year-Month column for grouping\n",
    "data['DATE'] = pd.to_datetime(data['DATE'])\n",
    "data['YEARMONTH'] = data['DATE'].dt.to_period('M')\n",
    "\n",
    "# Calculate key metrics: total sales, number of customers, transactions per customer\n",
    "metrics = data.groupby(['STORE_NBR', 'YEARMONTH']).agg(\n",
    "    totSales=('TOT_SALES', 'sum'),\n",
    "    nCustomers=('LYLTY_CARD_NBR', 'nunique'),\n",
    "    nTxnPerCust=('TXN_ID', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Function to calculate correlations\n",
    "def calculate_correlation(input_table, metric_col, trial_store):\n",
    "    results = []\n",
    "    trial_data = input_table[input_table['STORE_NBR'] == trial_store]\n",
    "    for store in input_table['STORE_NBR'].unique():\n",
    "        if store != trial_store:\n",
    "            control_data = input_table[input_table['STORE_NBR'] == store]\n",
    "            correlation = trial_data[metric_col].corr(control_data[metric_col])\n",
    "            results.append({'trial_store': trial_store, 'control_store': store, 'correlation': correlation})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Function to calculate magnitude distance\n",
    "def calculate_magnitude_distance(input_table, metric_col, trial_store):\n",
    "    results = []\n",
    "    trial_data = input_table[input_table['STORE_NBR'] == trial_store]\n",
    "    for store in input_table['STORE_NBR'].unique():\n",
    "        if store != trial_store:\n",
    "            control_data = input_table[input_table['STORE_NBR'] == store]\n",
    "            diff = abs(trial_data[metric_col].mean() - control_data[metric_col].mean())\n",
    "            min_val = input_table[metric_col].min()\n",
    "            max_val = input_table[metric_col].max()\n",
    "            mag_dist = 1 - (diff / (max_val - min_val))\n",
    "            results.append({'trial_store': trial_store, 'control_store': store, 'magnitude_distance': mag_dist})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Function to calculate final scores\n",
    "def calculate_final_score(correlation_df, magnitude_df):\n",
    "    merged = correlation_df.merge(magnitude_df, on=['trial_store', 'control_store'])\n",
    "    merged['final_score'] = 0.5 * merged['correlation'] + 0.5 * merged['magnitude_distance']\n",
    "    return merged\n",
    "\n",
    "# Pre-trial and trial periods\n",
    "pre_trial_period = metrics[metrics['YEARMONTH'] < '2019-02']\n",
    "trial_period = metrics[(metrics['YEARMONTH'] >= '2019-02') & (metrics['YEARMONTH'] <= '2019-04')]\n",
    "\n",
    "# Iterate over all trial stores\n",
    "trial_stores = [77, 86, 88]\n",
    "results = {}\n",
    "\n",
    "for trial_store in trial_stores:\n",
    "    print(f\"Processing trial store: {trial_store}\")\n",
    "\n",
    "    # Calculate correlations and magnitude distances\n",
    "    corr_tot_sales = calculate_correlation(pre_trial_period, 'totSales', trial_store)\n",
    "    mag_tot_sales = calculate_magnitude_distance(pre_trial_period, 'totSales', trial_store)\n",
    "\n",
    "    # Combine scores and find the best control store\n",
    "    final_scores = calculate_final_score(corr_tot_sales, mag_tot_sales)\n",
    "    best_control_store = final_scores.sort_values('final_score', ascending=False).iloc[0]['control_store']\n",
    "    print(f\"Best control store for trial store {trial_store}: {best_control_store}\")\n",
    "    results[trial_store] = best_control_store\n",
    "\n",
    "    # Scale control store sales to match trial store\n",
    "    trial_store_sales = pre_trial_period[\n",
    "        (pre_trial_period['STORE_NBR'] == trial_store)\n",
    "    ]['totSales'].sum()\n",
    "\n",
    "    control_store_sales = pre_trial_period[\n",
    "        (pre_trial_period['STORE_NBR'] == best_control_store)\n",
    "    ]['totSales'].sum()\n",
    "\n",
    "    if control_store_sales == 0:\n",
    "        print(f\"Warning: Control store {best_control_store} has zero total sales in the pre-trial period.\")\n",
    "        scaling_factor = 1\n",
    "    else:\n",
    "        scaling_factor = trial_store_sales / control_store_sales\n",
    "\n",
    "    # Add scaled_control_sales to metrics\n",
    "    metrics['scaled_control_sales'] = metrics.apply(\n",
    "        lambda row: row['totSales'] * scaling_factor if row['STORE_NBR'] == best_control_store else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Recreate pre_trial_period and trial_period to include scaled_control_sales\n",
    "    pre_trial_period = metrics[metrics['YEARMONTH'] < '2019-02']\n",
    "    trial_period = metrics[(metrics['YEARMONTH'] >= '2019-02') & (metrics['YEARMONTH'] <= '2019-04')]\n",
    "\n",
    "    # Debugging: Check pre_trial_period and trial_period\n",
    "    print(\"Pre-trial period data for scaled_control_sales:\")\n",
    "    print(pre_trial_period[pre_trial_period['STORE_NBR'] == best_control_store][['STORE_NBR', 'YEARMONTH', 'totSales', 'scaled_control_sales']])\n",
    "    print(\"Trial period data for scaled_control_sales:\")\n",
    "    print(trial_period[trial_period['STORE_NBR'] == best_control_store][['STORE_NBR', 'YEARMONTH', 'totSales', 'scaled_control_sales']])\n",
    "\n",
    "    # Calculate percentage difference\n",
    "    def calculate_percentage_difference(group):\n",
    "        if not group[group['STORE_NBR'] == best_control_store].empty and not group[group['STORE_NBR'] == trial_store].empty:\n",
    "            trial_sales = group[group['STORE_NBR'] == trial_store]['totSales'].values[0]\n",
    "            control_sales = group[group['STORE_NBR'] == best_control_store]['scaled_control_sales'].values[0]\n",
    "            return (trial_sales - control_sales) / control_sales\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    percentage_diff = trial_period.groupby('YEARMONTH').apply(calculate_percentage_difference)\n",
    "    print(f\"Percentage differences during trial period for store {trial_store}:\")\n",
    "    print(percentage_diff)\n",
    "\n",
    "    # Perform t-test for significance\n",
    "    pre_trial_diff = pre_trial_period[\n",
    "        pre_trial_period['STORE_NBR'] == trial_store\n",
    "    ]['totSales'] - pre_trial_period[\n",
    "        pre_trial_period['STORE_NBR'] == best_control_store\n",
    "    ]['scaled_control_sales']\n",
    "\n",
    "    # Ensure no missing values in pre_trial_diff\n",
    "    pre_trial_diff = pre_trial_diff.dropna()\n",
    "    percentage_diff = percentage_diff.dropna()\n",
    "\n",
    "    # Perform the t-test\n",
    "    if len(pre_trial_diff) > 0 and len(percentage_diff) > 0:\n",
    "        t_stat, p_value = ttest_ind(pre_trial_diff, percentage_diff)\n",
    "        print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "    else:\n",
    "        print(f\"Insufficient data for t-test between trial store {trial_store} and control store {best_control_store}.\")\n",
    "\n",
    "# Visualize sales trends\n",
    "sns.lineplot(data=metrics, x='YEARMONTH', y='totSales', hue='STORE_NBR')\n",
    "plt.title('Sales Trends During Trial and Pre-Trial Periods')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0d6e55-b66c-485f-80d9-fc809e199852",
   "metadata": {},
   "source": [
    "Initial Findings\n",
    "\n",
    "1. Best Control Store Selection\n",
    "\n",
    "\t•\tFor all trial stores (77, 86, and 88), the same store (STORE_NBR = 1) was selected as the best control store based on the combined correlation and magnitude distance scores.\n",
    "\t•\tThis could indicate that Store 1 has consistent metrics compared to the trial stores during the pre-trial period, making it the closest match across the board.\n",
    "\n",
    "2. Pre-Trial and Trial Period Data\n",
    "\n",
    "\t•\tPre-Trial Period (Scaled Sales):\n",
    "\t•\tThe scaled_control_sales column is calculated for the control store (STORE_NBR = 1) during the pre-trial period.\n",
    "\t•\tThe scaling factors seem to vary significantly for each trial store, as the scaled values differ notably for the same STORE_NBR.\n",
    "\t•\tTrial Period (Scaled Sales):\n",
    "\t•\tDuring the trial period, the scaled sales for Store 1 (scaled_control_sales) remain consistent across months, aligning with the scaling factor applied.\n",
    "\t•\tThe trial stores show varied performance when compared to these scaled values.\n",
    "\n",
    "3. Percentage Differences\n",
    "\n",
    "\t•\tTrial Store 77:\n",
    "\t•\tNegative differences in February (-0.1489) indicate a drop in sales compared to the control store.\n",
    "\t•\tMarch (0.1785) and April (0.1151) show positive differences, suggesting improved performance.\n",
    "\t•\tTrial Store 86:\n",
    "\t•\tMixed performance:\n",
    "\t•\tSlight drop in February (-0.0818).\n",
    "\t•\tImprovement in March (0.2063).\n",
    "\t•\tAlmost no difference in April (-0.0035).\n",
    "\t•\tTrial Store 88:\n",
    "\t•\tSimilar to Store 86, with mixed results:\n",
    "\t•\tSlight drop in February (-0.1015).\n",
    "\t•\tImprovement in March (0.1318) and April (0.1029).\n",
    "\n",
    "4. Statistical Testing\n",
    "\n",
    "\t•\tT-Tests for Significance:\n",
    "\t•\tFor all trial stores (77, 86, and 88), there is insufficient data to perform the t-tests.\n",
    "\t•\tThis may be due to missing or limited valid observations in either the pre_trial_diff or percentage_diff datasets after dropping NaN values.\n",
    "\n",
    "Key Takeaways\n",
    "\n",
    "\t1.\tBest Control Store Consistency:\n",
    "\t•\tThe repeated selection of Store 1 suggests that it may dominate as the closest match across metrics during the pre-trial period.\n",
    "\t•\tThis may indicate limited diversity in store behavior, potentially skewing control store selection.\n",
    "\t2.\tTrial Performance Variability:\n",
    "\t•\tAll trial stores show mixed performance during the trial period, with some months exhibiting improvement and others showing declines.\n",
    "\t3.\tInsufficient Data for T-Tests:\n",
    "\t•\tThe inability to perform t-tests highlights a limitation in the dataset. This could be due to:\n",
    "\t•\tMissing or insufficient data in the scaled metrics.\n",
    "\t•\tPoor alignment of trial and control stores in certain months.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0c4d0d5-0d0b-4ff7-9cf7-6834d65e00b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 264836 entries, 0 to 264835\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   DATE              264836 non-null  int64  \n",
      " 1   STORE_NBR         264836 non-null  int64  \n",
      " 2   LYLTY_CARD_NBR    264836 non-null  int64  \n",
      " 3   TXN_ID            264836 non-null  int64  \n",
      " 4   PROD_NBR          264836 non-null  int64  \n",
      " 5   PROD_NAME         264836 non-null  object \n",
      " 6   PROD_QTY          264836 non-null  int64  \n",
      " 7   TOT_SALES         264836 non-null  float64\n",
      " 8   LIFESTAGE         264836 non-null  object \n",
      " 9   PREMIUM_CUSTOMER  264836 non-null  object \n",
      "dtypes: float64(1), int64(6), object(3)\n",
      "memory usage: 20.2+ MB\n",
      "None\n",
      "\n",
      "Total Sales by Segment:\n",
      "                 LIFESTAGE PREMIUM_CUSTOMER  TOT_SALES\n",
      "6           OLDER FAMILIES           Budget  168363.25\n",
      "19   YOUNG SINGLES/COUPLES       Mainstream  157621.60\n",
      "13                RETIREES       Mainstream  155677.05\n",
      "15          YOUNG FAMILIES           Budget  139345.85\n",
      "9    OLDER SINGLES/COUPLES           Budget  136769.80\n",
      "10   OLDER SINGLES/COUPLES       Mainstream  133393.80\n",
      "11   OLDER SINGLES/COUPLES          Premium  132263.15\n",
      "12                RETIREES           Budget  113147.80\n",
      "7           OLDER FAMILIES       Mainstream  103445.55\n",
      "14                RETIREES          Premium   97646.05\n",
      "16          YOUNG FAMILIES       Mainstream   92788.75\n",
      "1   MIDAGE SINGLES/COUPLES       Mainstream   90803.85\n",
      "17          YOUNG FAMILIES          Premium   84025.50\n",
      "8           OLDER FAMILIES          Premium   81958.40\n",
      "18   YOUNG SINGLES/COUPLES           Budget   61141.60\n",
      "2   MIDAGE SINGLES/COUPLES          Premium   58432.65\n",
      "20   YOUNG SINGLES/COUPLES          Premium   41642.10\n",
      "0   MIDAGE SINGLES/COUPLES           Budget   35514.80\n",
      "3             NEW FAMILIES           Budget   21928.45\n",
      "4             NEW FAMILIES       Mainstream   17013.90\n",
      "5             NEW FAMILIES          Premium   11491.10\n",
      "\n",
      "Average Product Quantity by Segment:\n",
      "                 LIFESTAGE PREMIUM_CUSTOMER  PROD_QTY\n",
      "8           OLDER FAMILIES          Premium  1.980969\n",
      "7           OLDER FAMILIES       Mainstream  1.948610\n",
      "6           OLDER FAMILIES           Budget  1.945812\n",
      "15          YOUNG FAMILIES           Budget  1.940749\n",
      "16          YOUNG FAMILIES       Mainstream  1.940342\n",
      "17          YOUNG FAMILIES          Premium  1.937732\n",
      "11   OLDER SINGLES/COUPLES          Premium  1.914273\n",
      "9    OLDER SINGLES/COUPLES           Budget  1.913403\n",
      "1   MIDAGE SINGLES/COUPLES       Mainstream  1.911656\n",
      "10   OLDER SINGLES/COUPLES       Mainstream  1.910525\n",
      "14                RETIREES          Premium  1.900122\n",
      "12                RETIREES           Budget  1.892244\n",
      "0   MIDAGE SINGLES/COUPLES           Budget  1.891633\n",
      "2   MIDAGE SINGLES/COUPLES          Premium  1.889727\n",
      "13                RETIREES       Mainstream  1.887543\n",
      "5             NEW FAMILIES          Premium  1.860919\n",
      "4             NEW FAMILIES       Mainstream  1.857634\n",
      "3             NEW FAMILIES           Budget  1.853910\n",
      "19   YOUNG SINGLES/COUPLES       Mainstream  1.852498\n",
      "20   YOUNG SINGLES/COUPLES          Premium  1.804012\n",
      "18   YOUNG SINGLES/COUPLES           Budget  1.803830\n",
      "\n",
      "Pack Size Preference by Segment:\n",
      "                 LIFESTAGE PREMIUM_CUSTOMER PACK_SIZE  TOT_SALES\n",
      "134         OLDER FAMILIES           Budget       175    42204.7\n",
      "281               RETIREES       Mainstream       175    38242.7\n",
      "407  YOUNG SINGLES/COUPLES       Mainstream       175    37967.9\n",
      "323         YOUNG FAMILIES           Budget       175    35634.8\n",
      "197  OLDER SINGLES/COUPLES           Budget       175    34497.0\n",
      "239  OLDER SINGLES/COUPLES          Premium       175    33393.3\n",
      "218  OLDER SINGLES/COUPLES       Mainstream       175    33041.6\n",
      "260               RETIREES           Budget       175    28977.1\n",
      "130         OLDER FAMILIES           Budget       150    27017.1\n",
      "155         OLDER FAMILIES       Mainstream       175    25975.4\n",
      "\n",
      "Top Brands by Segment:\n",
      "                  LIFESTAGE PREMIUM_CUSTOMER   BRAND  TOT_SALES\n",
      "563   YOUNG SINGLES/COUPLES       Mainstream  Kettle    35423.6\n",
      "186          OLDER FAMILIES           Budget  Kettle    32058.0\n",
      "389                RETIREES       Mainstream  Kettle    31652.4\n",
      "273   OLDER SINGLES/COUPLES           Budget  Kettle    29066.4\n",
      "331   OLDER SINGLES/COUPLES          Premium  Kettle    27943.4\n",
      "302   OLDER SINGLES/COUPLES       Mainstream  Kettle    26852.8\n",
      "447          YOUNG FAMILIES           Budget  Kettle    26369.6\n",
      "360                RETIREES           Budget  Kettle    24340.0\n",
      "418                RETIREES          Premium  Kettle    20922.4\n",
      "41   MIDAGE SINGLES/COUPLES       Mainstream  Kettle    20231.8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the transaction and purchase behavior datasets\n",
    "transaction_data = pd.read_excel('QVI_transaction_data.xlsx')\n",
    "purchase_behaviour = pd.read_csv('QVI_purchase_behaviour.csv')\n",
    "\n",
    "# Merge datasets on LYLTY_CARD_NBR\n",
    "merged_data = transaction_data.merge(purchase_behaviour, on='LYLTY_CARD_NBR', how='inner')\n",
    "\n",
    "# Check high-level summary\n",
    "print(\"Merged Dataset Info:\")\n",
    "print(merged_data.info())\n",
    "\n",
    "\n",
    "# Total sales by segment\n",
    "sales_by_segment = merged_data.groupby(['LIFESTAGE', 'PREMIUM_CUSTOMER'])['TOT_SALES'].sum().reset_index()\n",
    "sales_by_segment = sales_by_segment.sort_values(by='TOT_SALES', ascending=False)\n",
    "print(\"\\nTotal Sales by Segment:\")\n",
    "print(sales_by_segment)\n",
    "\n",
    "\n",
    "# Average product quantity purchased by segment\n",
    "avg_qty_by_segment = merged_data.groupby(['LIFESTAGE', 'PREMIUM_CUSTOMER'])['PROD_QTY'].mean().reset_index()\n",
    "avg_qty_by_segment = avg_qty_by_segment.sort_values(by='PROD_QTY', ascending=False)\n",
    "print(\"\\nAverage Product Quantity by Segment:\")\n",
    "print(avg_qty_by_segment)\n",
    "\n",
    "# Analyze preferred pack sizes\n",
    "# Extract pack size (assuming it’s embedded in `PROD_NAME` like 'Xg' or 'XXg')\n",
    "merged_data['PACK_SIZE'] = merged_data['PROD_NAME'].str.extract(r'(\\d+)[gG]')\n",
    "pack_size_by_segment = merged_data.groupby(['LIFESTAGE', 'PREMIUM_CUSTOMER', 'PACK_SIZE'])['TOT_SALES'].sum().reset_index()\n",
    "pack_size_by_segment = pack_size_by_segment.sort_values(by='TOT_SALES', ascending=False)\n",
    "print(\"\\nPack Size Preference by Segment:\")\n",
    "print(pack_size_by_segment.head(10))\n",
    "\n",
    "# Analyze preferred brands\n",
    "# Extract brand name (assuming it’s the first word in `PROD_NAME`)\n",
    "merged_data['BRAND'] = merged_data['PROD_NAME'].str.split().str[0]\n",
    "brand_by_segment = merged_data.groupby(['LIFESTAGE', 'PREMIUM_CUSTOMER', 'BRAND'])['TOT_SALES'].sum().reset_index()\n",
    "brand_by_segment = brand_by_segment.sort_values(by='TOT_SALES', ascending=False)\n",
    "print(\"\\nTop Brands by Segment:\")\n",
    "print(brand_by_segment.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "772826e6-6c41-4684-b8c5-8caa53374fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert YEARMONTH to Period type\n",
    "if not isinstance(metrics['YEARMONTH'].dtype, pd.PeriodDtype):\n",
    "    metrics['YEARMONTH'] = pd.to_datetime(metrics['YEARMONTH'], errors='coerce').dt.to_period('M')\n",
    "\n",
    "# Convert totSales to numeric and handle invalid values\n",
    "metrics['totSales'] = pd.to_numeric(metrics['totSales'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c249a5ce-5828-4b4b-8105-a47d6125e0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      STORE_NBR YEARMONTH  totSales  nCustomers  nTxnPerCust  \\\n",
      "12            2   2018-07     150.8          39           41   \n",
      "13            2   2018-08     193.8          39           43   \n",
      "14            2   2018-09     154.4          36           37   \n",
      "15            2   2018-10     167.8          41           43   \n",
      "16            2   2018-11     162.9          39           40   \n",
      "...         ...       ...       ...         ...          ...   \n",
      "3164        272   2019-02     395.5          45           48   \n",
      "3165        272   2019-03     442.3          50           53   \n",
      "3166        272   2019-04     445.1          54           56   \n",
      "3167        272   2019-05     314.6          34           40   \n",
      "3168        272   2019-06     312.1          34           37   \n",
      "\n",
      "      scaled_control_sales  \n",
      "12                     NaN  \n",
      "13                     NaN  \n",
      "14                     NaN  \n",
      "15                     NaN  \n",
      "16                     NaN  \n",
      "...                    ...  \n",
      "3164                   NaN  \n",
      "3165                   NaN  \n",
      "3166                   NaN  \n",
      "3167                   NaN  \n",
      "3168                   NaN  \n",
      "\n",
      "[3157 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identify rows with NaN in critical columns\n",
    "print(metrics[metrics.isna().any(axis=1)])\n",
    "\n",
    "# Drop rows with missing or invalid values\n",
    "metrics.dropna(subset=['YEARMONTH', 'totSales', 'STORE_NBR'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af06d91c-5c2c-4db8-95b4-b0b308f54ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
